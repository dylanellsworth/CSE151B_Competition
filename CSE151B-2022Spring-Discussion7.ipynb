{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "        \n",
    "    elif split == 'val':\n",
    "        f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(city = city, split = split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a174510",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ArgoverseDataset(city = city, split = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a44d7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create a DataLoader class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5b7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class Pred(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbc1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Pred()\n",
    "opt = optim.Adam(pred.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4725237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 380084.35665384395\n",
      "epoch 1 loss: 362147.8741190479\n",
      "epoch 2 loss: 330976.7309799203\n",
      "epoch 3 loss: 318837.74728825135\n",
      "epoch 4 loss: 293762.63018563384\n",
      "epoch 5 loss: 276665.68182098796\n",
      "epoch 6 loss: 279099.96090108465\n",
      "epoch 7 loss: 264577.7583283546\n",
      "epoch 8 loss: 253173.51524546143\n",
      "epoch 9 loss: 236803.1520662675\n",
      "epoch 10 loss: 226774.93254397958\n",
      "epoch 11 loss: 223561.01672311084\n",
      "epoch 12 loss: 230691.70616409404\n",
      "epoch 13 loss: 216628.63605745908\n",
      "epoch 14 loss: 194775.48904852237\n",
      "epoch 15 loss: 215619.48243407963\n",
      "epoch 16 loss: 187808.10729687137\n",
      "epoch 17 loss: 197587.01937167978\n",
      "epoch 18 loss: 196530.53910641297\n",
      "epoch 19 loss: 171802.09166252127\n",
      "epoch 20 loss: 189301.11568747292\n",
      "epoch 21 loss: 177610.2464888276\n",
      "epoch 22 loss: 179871.48778562128\n",
      "epoch 23 loss: 176314.51634515094\n",
      "epoch 24 loss: 164947.6889748319\n",
      "epoch 25 loss: 166403.958102337\n",
      "epoch 26 loss: 155779.4059226927\n",
      "epoch 27 loss: 155827.97740115414\n",
      "epoch 28 loss: 140066.44174000045\n",
      "epoch 29 loss: 154509.16151156786\n",
      "epoch 30 loss: 143850.51535744013\n",
      "epoch 31 loss: 135664.82645048204\n",
      "epoch 32 loss: 141012.7959244113\n",
      "epoch 33 loss: 141727.43852815658\n",
      "epoch 34 loss: 139012.3214932681\n",
      "epoch 35 loss: 118570.63721475065\n",
      "epoch 36 loss: 127957.91884781844\n",
      "epoch 37 loss: 114037.59914686502\n",
      "epoch 38 loss: 134489.29974454173\n",
      "epoch 39 loss: 125687.28782123978\n",
      "epoch 40 loss: 124069.60206545457\n",
      "epoch 41 loss: 126108.65489584504\n",
      "epoch 42 loss: 113067.18291380852\n",
      "epoch 43 loss: 128440.56282092458\n",
      "epoch 44 loss: 125158.28024942949\n",
      "epoch 45 loss: 114454.09082932243\n",
      "epoch 46 loss: 112804.88901226236\n",
      "epoch 47 loss: 118541.95304559807\n",
      "epoch 48 loss: 107750.9487460078\n",
      "epoch 49 loss: 114271.70278008567\n",
      "epoch 50 loss: 123038.69403435376\n",
      "epoch 51 loss: 117250.52086607419\n",
      "epoch 52 loss: 105938.94365398686\n",
      "epoch 53 loss: 110784.76237898006\n",
      "epoch 54 loss: 115471.20931272816\n",
      "epoch 55 loss: 108429.54271081812\n",
      "epoch 56 loss: 114369.92910941096\n",
      "epoch 57 loss: 104032.74330709428\n",
      "epoch 58 loss: 111283.25878302833\n",
      "epoch 59 loss: 103997.79008716006\n",
      "epoch 60 loss: 102001.42076180951\n",
      "epoch 61 loss: 109752.00630407852\n",
      "epoch 62 loss: 102110.62680524147\n",
      "epoch 63 loss: 98642.65222563336\n",
      "epoch 64 loss: 97114.66665253424\n",
      "epoch 65 loss: 100495.80817911674\n",
      "epoch 66 loss: 91500.2332900948\n",
      "epoch 67 loss: 100959.94853781137\n",
      "epoch 68 loss: 91206.19699130657\n",
      "epoch 69 loss: 96396.7437344657\n",
      "epoch 70 loss: 92862.23786435186\n",
      "epoch 71 loss: 94671.792931303\n",
      "epoch 72 loss: 92446.96899171252\n",
      "epoch 73 loss: 94881.58052124757\n",
      "epoch 74 loss: 97348.59778232493\n",
      "epoch 75 loss: 93018.91194624761\n",
      "epoch 76 loss: 90383.09992168893\n",
      "epoch 77 loss: 92604.44402289725\n",
      "epoch 78 loss: 87709.8041750746\n",
      "epoch 79 loss: 98091.90529539569\n",
      "epoch 80 loss: 91388.48057201377\n",
      "epoch 81 loss: 87374.43635951773\n",
      "epoch 82 loss: 89462.06662600327\n",
      "epoch 83 loss: 91219.92584951408\n",
      "epoch 84 loss: 88844.43895936916\n",
      "epoch 85 loss: 86856.22567044864\n",
      "epoch 86 loss: 90448.55241209074\n",
      "epoch 87 loss: 84477.58455089289\n",
      "epoch 88 loss: 90478.0537857769\n",
      "epoch 89 loss: 83944.45499220057\n",
      "epoch 90 loss: 87867.321554297\n",
      "epoch 91 loss: 85053.20909264269\n",
      "epoch 92 loss: 81407.61647540302\n",
      "epoch 93 loss: 86684.99356778695\n",
      "epoch 94 loss: 81807.65689394873\n",
      "epoch 95 loss: 83840.42052180285\n",
      "epoch 96 loss: 88390.67696551859\n",
      "epoch 97 loss: 81193.1066004609\n",
      "epoch 98 loss: 77774.90750181832\n",
      "epoch 99 loss: 87289.60808291387\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "        preds = pred(inp)\n",
    "        loss = ((preds - out) ** 2).sum()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print('epoch {} loss: {}'.format(epoch, total_loss / len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da57dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 48721.0293654672\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz)\n",
    "\n",
    "val_loss = 0\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    preds = pred(inp)\n",
    "    loss = ((preds - out) ** 2).sum()\n",
    "\n",
    "    val_loss += loss.item()\n",
    "print('loss: {}'.format(val_loss / len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b5e4",
   "metadata": {},
   "source": [
    "## Sample a batch of data and visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6507c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 50, 2]) torch.Size([4, 60, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    print(inp.shape, out.shape)\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO:\n",
    "      implement your Deep learning model\n",
    "      implement training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00333419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2d4884ef49a982a1eb5c43e5ae8a96487ae20917b7a89575cf03e86c2c63cb9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
