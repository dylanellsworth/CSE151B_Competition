{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad605299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"/home/jmryan/cse151B/argo2/\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "    inputs = pickle.load(open(f_in, \"rb\"))\n",
    "    inputs = np.asarray(inputs)\n",
    "    \n",
    "    outputs = None\n",
    "    \n",
    "    if split==\"train\":\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'palo-alto' \n",
    "split = 'train'\n",
    "train_dataset  = ArgoverseDataset(city = city, split = split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78e9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edcdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452/153573212.py:11: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def show_sample_batch(sample_batch):\n",
    "    \"\"\"visualize the trajectory for a batch of samples\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i,:,0], inp[i,:,1])\n",
    "        axs[i].scatter(out[i,:,0], out[i,:,1])\n",
    "\n",
    "        \n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "    inp, out = sample_batch\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "      implement your Deep learning model\n",
    "      implement training routine\n",
    "    \"\"\"\n",
    "    show_sample_batch(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create a Torch.Dataset class for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee72ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cf29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/home/jmryan/cse151B/argo2/train\"\n",
    "x = pickle.load(open(ROOT_PATH + '/austin_inputs', 'rb'))\n",
    "y = pickle.load(open(ROOT_PATH + '/austin_outputs', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4b30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_x = pickle.load(open(ROOT_PATH + '/miami_inputs', 'rb'))\n",
    "m_y = pickle.load(open(ROOT_PATH + '/miami_outputs', 'rb'))\n",
    "p_x = pickle.load(open(ROOT_PATH + '/pittsburgh_inputs', 'rb'))\n",
    "p_y = pickle.load(open(ROOT_PATH + '/pittsburgh_outputs', 'rb'))\n",
    "d_x = pickle.load(open(ROOT_PATH + '/dearborn_inputs', 'rb'))\n",
    "d_y = pickle.load(open(ROOT_PATH + '/dearborn_outputs', 'rb'))\n",
    "w_x = pickle.load(open(ROOT_PATH + '/washington-dc_inputs', 'rb'))\n",
    "w_y = pickle.load(open(ROOT_PATH + '/washington-dc_outputs', 'rb'))\n",
    "pa_x = pickle.load(open(ROOT_PATH + '/palo-alto_inputs', 'rb'))\n",
    "pa_y = pickle.load(open(ROOT_PATH + '/palo-alto_outputs', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79200527",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = [m_x,p_x,d_x,w_x,pa_x]\n",
    "y_all = [m_y,p_y,d_y,w_y,pa_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e340ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99/2434146055.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, device=device)\n",
      "/tmp/ipykernel_99/2434146055.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(x, device=device)\n",
    "y = torch.tensor(y, device=device)\n",
    "new_y = torch.empty((2582460, 50, 2), device= device)\n",
    "new_x =  torch.empty((2582460, 50, 2), device= device)\n",
    "count = 0\n",
    "for i in range(len(x)):\n",
    "    feat = torch.cat([x[i],y[i]])\n",
    "    for j in range(60):\n",
    "        new_x[count] = feat[j:j+50,:]\n",
    "        new_y[count] =  feat[j+1:j+51,:]\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5df0573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "all_x = []\n",
    "all_y = []\n",
    "for k in range(len(x_all)):\n",
    "    print(k)\n",
    "    temp_x = torch.empty((len(x_all[k]) * 60, 50, 2), device=device)\n",
    "    temp_y = torch.empty((len(x_all[k]) * 60, 50, 2), device=device)\n",
    "\n",
    "    curr_x = torch.tensor(x_all[k],device=device)\n",
    "    curr_y = torch.tensor(y_all[k], device=device)\n",
    "    count = 0\n",
    "    for i in range(len(curr_x)):\n",
    "        feat = torch.cat([curr_x[i],curr_y[i]])\n",
    "        for j in range(60):\n",
    "            temp_x[count] = feat[j:j+50,:]\n",
    "            temp_y[count] =  feat[j+1:j+51,:]\n",
    "            count += 1\n",
    "    all_x.append(temp_x)\n",
    "    all_y.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1169abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x.append(new_x)\n",
    "all_y.append(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb9c16e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2582460, 50, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d12601d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(x, device = device)\n",
    "y = torch.tensor(y, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ddbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = torch.empty((len(x),2), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ab8054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.cat((x[0],y[0]), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc055f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84/2937342763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m     \"\"\"\n\u001b[0;32m-> 4811\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4812\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "np.append(x[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9a8d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(x)):\n",
    "    final = torch.cat((final, torch.cat((x[i], y[i]), dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc57215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4777551, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "151b14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, num_hidden, num_layers, input_size, seq_len, batch_size, device):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        self.num_hidden = num_hidden\n",
    "        self.proj_size = 2\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=num_hidden, num_layers=num_layers, batch_first=True, device=device)\n",
    "#         self.fc = torch.nn.Linear(hidden_size, 128, device=device)\n",
    "       # self.lstm2 = torch.nn.LSTM(input_size=input_size, hidden_size=num_hidden, num_layers=num_layers, batch_first=True, device=device)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear = torch.nn.Linear(in_features = num_hidden, out_features = 100, device=device)\n",
    "        self.h  = torch.rand(self.num_layers, batch_size, self.num_hidden, device=device)\n",
    "        self.c = torch.rand(self.num_layers, batch_size, self.num_hidden, device=device)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # Propagate input through LSTM\n",
    "        h  = torch.rand(self.num_layers, self.batch_size, self.num_hidden, device=device)\n",
    "        c = torch.rand(self.num_layers, self.batch_size, self.num_hidden, device=device)\n",
    "        #h2  = torch.rand(self.num_layers, self.batch_size, self.num_hidden, device=device)\n",
    "        #c2 = torch.rand(self.num_layers, self.batch_size, self.num_hidden, device=device)\n",
    "        output, (h, c) = self.lstm(x, (h, c)) #lstm with input, hidden, and internal state\n",
    "        #output, (h,c) = self.lstm2(h, (h2,c2))\n",
    "        output = self.linear(h)\n",
    "        output = torch.reshape(output, (self.batch_size, self.seq_len, self.input_size))\n",
    "#         hn = hn.view(-1, self.num_hidden) #reshaping the data for Dense layer next\n",
    "      #  //out = self.relu(hn) \n",
    "     #   //out = self.relu(out) #relu\n",
    "    #out = self.fc(out) #Final Output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61122d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = np.array(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67fe38b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fb43a33adf0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "num_epochs = 100 #1000 epochs\n",
    "learning_rate = 0.001 #0.001 lr\n",
    "\n",
    "input_size = 2 #number of features\n",
    "hidden_size = 128 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "#number of output classes \n",
    "lstm = LSTM(hidden_size, num_layers, input_size, 50, 1000, device)\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb8ad2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2831fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1550038.62500\n",
      "Epoch: 1, loss: 1227097.25000\n",
      "Epoch: 2, loss: 916522.68750\n",
      "Epoch: 3, loss: 770832.25000\n",
      "Epoch: 4, loss: 701812.43750\n",
      "Epoch: 5, loss: 559282.75000\n",
      "Epoch: 6, loss: 455944.09375\n",
      "Epoch: 7, loss: 342184.37500\n",
      "Epoch: 8, loss: 300084.87500\n",
      "Epoch: 9, loss: 230136.81250\n",
      "Epoch: 10, loss: 196574.59375\n",
      "Epoch: 11, loss: 173345.21875\n",
      "Epoch: 12, loss: 131042.29688\n",
      "Epoch: 13, loss: 105493.14062\n",
      "Epoch: 14, loss: 117499.24219\n",
      "Epoch: 15, loss: 85170.40625\n",
      "Epoch: 16, loss: 137158.85938\n",
      "Epoch: 17, loss: 108051.41406\n",
      "Epoch: 18, loss: 162010.64062\n",
      "Epoch: 19, loss: 80562.24219\n",
      "Epoch: 20, loss: 73112.44531\n",
      "Epoch: 21, loss: 192089.32812\n",
      "Epoch: 22, loss: 101979.99219\n",
      "Epoch: 23, loss: 122745.36719\n",
      "Epoch: 24, loss: 73207.00781\n",
      "Epoch: 25, loss: 82827.96875\n",
      "Epoch: 26, loss: 62664.28125\n",
      "Epoch: 27, loss: 85124.80469\n",
      "Epoch: 28, loss: 74182.28125\n",
      "Epoch: 29, loss: 46632.05078\n",
      "Epoch: 30, loss: 31574.59375\n",
      "Epoch: 31, loss: 57600.67188\n",
      "Epoch: 32, loss: 78185.71875\n",
      "Epoch: 33, loss: 63404.18750\n",
      "Epoch: 34, loss: 44428.83984\n",
      "Epoch: 35, loss: 91365.10156\n",
      "Epoch: 36, loss: 52742.55469\n",
      "Epoch: 37, loss: 40847.67578\n",
      "Epoch: 38, loss: 50161.89062\n",
      "Epoch: 39, loss: 74839.49219\n",
      "Epoch: 40, loss: 47826.51562\n",
      "Epoch: 41, loss: 53000.59375\n",
      "Epoch: 42, loss: 92804.91406\n",
      "Epoch: 43, loss: 35360.97266\n",
      "Epoch: 44, loss: 65381.62891\n",
      "Epoch: 45, loss: 121765.62500\n",
      "Epoch: 46, loss: 61727.32812\n",
      "Epoch: 47, loss: 26681.59766\n",
      "Epoch: 48, loss: 38575.71094\n",
      "Epoch: 49, loss: 73409.28125\n",
      "Epoch: 50, loss: 46224.00391\n",
      "Epoch: 51, loss: 38152.80859\n",
      "Epoch: 52, loss: 44126.30859\n",
      "Epoch: 53, loss: 44247.82422\n",
      "Epoch: 54, loss: 39061.05859\n",
      "Epoch: 55, loss: 26121.32617\n",
      "Epoch: 56, loss: 60885.32812\n",
      "Epoch: 57, loss: 30678.34180\n",
      "Epoch: 58, loss: 55675.04688\n",
      "Epoch: 59, loss: 43656.50781\n",
      "Epoch: 60, loss: 57842.12109\n",
      "Epoch: 61, loss: 32393.37500\n",
      "Epoch: 62, loss: 28366.41992\n",
      "Epoch: 63, loss: 81129.57031\n",
      "Epoch: 64, loss: 55848.46484\n",
      "Epoch: 65, loss: 81535.39844\n",
      "Epoch: 66, loss: 65464.69922\n",
      "Epoch: 67, loss: 137507.51562\n",
      "Epoch: 68, loss: 102609.66406\n",
      "Epoch: 69, loss: 65532.53906\n",
      "Epoch: 70, loss: 63233.92969\n",
      "Epoch: 71, loss: 74420.79688\n",
      "Epoch: 72, loss: 83750.91406\n",
      "Epoch: 73, loss: 85862.69531\n",
      "Epoch: 74, loss: 70399.41406\n",
      "Epoch: 75, loss: 77029.52344\n",
      "Epoch: 76, loss: 83846.25000\n",
      "Epoch: 77, loss: 126930.88281\n",
      "Epoch: 78, loss: 91419.09375\n",
      "Epoch: 79, loss: 98328.83594\n",
      "Epoch: 80, loss: 114238.07812\n",
      "Epoch: 81, loss: 180041.42188\n",
      "Epoch: 82, loss: 73649.93750\n",
      "Epoch: 83, loss: 113351.68750\n",
      "Epoch: 84, loss: 135633.67188\n",
      "Epoch: 85, loss: 156951.06250\n",
      "Epoch: 86, loss: 260652.53125\n",
      "Epoch: 87, loss: 166431.93750\n",
      "Epoch: 88, loss: 135325.70312\n",
      "Epoch: 89, loss: 102061.32812\n",
      "Epoch: 90, loss: 99805.33594\n",
      "Epoch: 91, loss: 71302.50000\n",
      "Epoch: 92, loss: 66413.22656\n",
      "Epoch: 93, loss: 107882.77344\n",
      "Epoch: 94, loss: 98743.11719\n",
      "Epoch: 95, loss: 100431.80469\n",
      "Epoch: 96, loss: 58020.35547\n",
      "Epoch: 97, loss: 107068.29688\n",
      "Epoch: 98, loss: 80616.92188\n",
      "Epoch: 99, loss: 88343.68750\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(all_x)):\n",
    "        \n",
    "        t = data_iter(1000, all_x[i], all_y[i])\n",
    "        count = 1\n",
    "        for x,y in t:\n",
    "            if x.shape[0] != 1000:\n",
    "                continue\n",
    "            outputs = lstm.forward(\n",
    "                x.float()) #forward pass\n",
    "            optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "          # obtain the loss function\n",
    "                #print(outputs[:,:,-1])\n",
    "                #print(outputs.shape)\n",
    "        #         print(y.float())\n",
    "        #         print(y.float().shape)\n",
    "            loss = criterion(outputs[:,-1,:], y.float()[:,-1,:])\n",
    "                #print(loss)\n",
    "            loss.backward(retain_graph=True) #calculates the loss of the loss function\n",
    "\n",
    "            optimizer.step() #improve from loss, i.e backprop\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "130af362",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,b = next(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fc62e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0193e+02,  1.1567e+03],\n",
       "         [-2.0180e+02,  1.1567e+03],\n",
       "         [-2.0167e+02,  1.1567e+03],\n",
       "         [-2.0154e+02,  1.1566e+03],\n",
       "         [-2.0141e+02,  1.1566e+03],\n",
       "         [-2.0129e+02,  1.1566e+03],\n",
       "         [-2.0116e+02,  1.1565e+03],\n",
       "         [-2.0104e+02,  1.1565e+03],\n",
       "         [-2.0092e+02,  1.1565e+03],\n",
       "         [-2.0079e+02,  1.1564e+03],\n",
       "         [-2.0067e+02,  1.1564e+03],\n",
       "         [-2.0055e+02,  1.1564e+03],\n",
       "         [-2.0043e+02,  1.1563e+03],\n",
       "         [-2.0031e+02,  1.1563e+03],\n",
       "         [-2.0019e+02,  1.1562e+03],\n",
       "         [-2.0007e+02,  1.1562e+03],\n",
       "         [-1.9995e+02,  1.1562e+03],\n",
       "         [-1.9983e+02,  1.1561e+03],\n",
       "         [-1.9971e+02,  1.1561e+03],\n",
       "         [-1.9959e+02,  1.1560e+03],\n",
       "         [-1.9947e+02,  1.1560e+03],\n",
       "         [-1.9934e+02,  1.1560e+03],\n",
       "         [-1.9921e+02,  1.1560e+03],\n",
       "         [-1.9908e+02,  1.1559e+03],\n",
       "         [-1.9894e+02,  1.1559e+03],\n",
       "         [-1.9879e+02,  1.1559e+03],\n",
       "         [-1.9864e+02,  1.1558e+03],\n",
       "         [-1.9849e+02,  1.1558e+03],\n",
       "         [-1.9835e+02,  1.1558e+03],\n",
       "         [-1.9821e+02,  1.1558e+03],\n",
       "         [-1.9807e+02,  1.1557e+03],\n",
       "         [-1.9793e+02,  1.1557e+03],\n",
       "         [-1.9780e+02,  1.1557e+03],\n",
       "         [-1.9766e+02,  1.1557e+03],\n",
       "         [-1.9752e+02,  1.1556e+03],\n",
       "         [-1.9739e+02,  1.1556e+03],\n",
       "         [-1.9725e+02,  1.1556e+03],\n",
       "         [-1.9712e+02,  1.1555e+03],\n",
       "         [-1.9698e+02,  1.1555e+03],\n",
       "         [-1.9684e+02,  1.1555e+03],\n",
       "         [-1.9669e+02,  1.1554e+03],\n",
       "         [-1.9653e+02,  1.1554e+03],\n",
       "         [-1.9638e+02,  1.1553e+03],\n",
       "         [-1.9623e+02,  1.1553e+03],\n",
       "         [-1.9610e+02,  1.1553e+03],\n",
       "         [-1.9598e+02,  1.1553e+03],\n",
       "         [-1.9589e+02,  1.1552e+03],\n",
       "         [-1.9580e+02,  1.1552e+03],\n",
       "         [-1.9573e+02,  1.1552e+03],\n",
       "         [-1.9568e+02,  1.1552e+03]],\n",
       "\n",
       "        [[ 2.2589e+02, -7.6852e+02],\n",
       "         [ 2.2597e+02, -7.6856e+02],\n",
       "         [ 2.2605e+02, -7.6859e+02],\n",
       "         [ 2.2612e+02, -7.6862e+02],\n",
       "         [ 2.2619e+02, -7.6865e+02],\n",
       "         [ 2.2626e+02, -7.6868e+02],\n",
       "         [ 2.2634e+02, -7.6870e+02],\n",
       "         [ 2.2642e+02, -7.6872e+02],\n",
       "         [ 2.2649e+02, -7.6875e+02],\n",
       "         [ 2.2658e+02, -7.6878e+02],\n",
       "         [ 2.2667e+02, -7.6881e+02],\n",
       "         [ 2.2676e+02, -7.6884e+02],\n",
       "         [ 2.2684e+02, -7.6888e+02],\n",
       "         [ 2.2693e+02, -7.6892e+02],\n",
       "         [ 2.2701e+02, -7.6895e+02],\n",
       "         [ 2.2709e+02, -7.6899e+02],\n",
       "         [ 2.2717e+02, -7.6902e+02],\n",
       "         [ 2.2724e+02, -7.6905e+02],\n",
       "         [ 2.2731e+02, -7.6907e+02],\n",
       "         [ 2.2738e+02, -7.6909e+02],\n",
       "         [ 2.2745e+02, -7.6911e+02],\n",
       "         [ 2.2753e+02, -7.6914e+02],\n",
       "         [ 2.2760e+02, -7.6916e+02],\n",
       "         [ 2.2768e+02, -7.6918e+02],\n",
       "         [ 2.2775e+02, -7.6920e+02],\n",
       "         [ 2.2783e+02, -7.6922e+02],\n",
       "         [ 2.2791e+02, -7.6925e+02],\n",
       "         [ 2.2799e+02, -7.6926e+02],\n",
       "         [ 2.2807e+02, -7.6928e+02],\n",
       "         [ 2.2815e+02, -7.6929e+02],\n",
       "         [ 2.2823e+02, -7.6930e+02],\n",
       "         [ 2.2831e+02, -7.6931e+02],\n",
       "         [ 2.2840e+02, -7.6933e+02],\n",
       "         [ 2.2848e+02, -7.6934e+02],\n",
       "         [ 2.2857e+02, -7.6936e+02],\n",
       "         [ 2.2865e+02, -7.6937e+02],\n",
       "         [ 2.2874e+02, -7.6940e+02],\n",
       "         [ 2.2883e+02, -7.6942e+02],\n",
       "         [ 2.2893e+02, -7.6945e+02],\n",
       "         [ 2.2903e+02, -7.6947e+02],\n",
       "         [ 2.2913e+02, -7.6949e+02],\n",
       "         [ 2.2923e+02, -7.6950e+02],\n",
       "         [ 2.2933e+02, -7.6952e+02],\n",
       "         [ 2.2943e+02, -7.6953e+02],\n",
       "         [ 2.2952e+02, -7.6954e+02],\n",
       "         [ 2.2960e+02, -7.6955e+02],\n",
       "         [ 2.2967e+02, -7.6954e+02],\n",
       "         [ 2.2973e+02, -7.6954e+02],\n",
       "         [ 2.2978e+02, -7.6953e+02],\n",
       "         [ 2.2982e+02, -7.6953e+02]],\n",
       "\n",
       "        [[-5.8820e+02,  1.1246e+00],\n",
       "         [-5.8802e+02,  1.8020e+00],\n",
       "         [-5.8780e+02,  2.4644e+00],\n",
       "         [-5.8753e+02,  3.1044e+00],\n",
       "         [-5.8726e+02,  3.7527e+00],\n",
       "         [-5.8700e+02,  4.4175e+00],\n",
       "         [-5.8674e+02,  5.0842e+00],\n",
       "         [-5.8648e+02,  5.7455e+00],\n",
       "         [-5.8622e+02,  6.4070e+00],\n",
       "         [-5.8598e+02,  7.0658e+00],\n",
       "         [-5.8575e+02,  7.7096e+00],\n",
       "         [-5.8553e+02,  8.3435e+00],\n",
       "         [-5.8530e+02,  8.9732e+00],\n",
       "         [-5.8508e+02,  9.5996e+00],\n",
       "         [-5.8485e+02,  1.0228e+01],\n",
       "         [-5.8463e+02,  1.0850e+01],\n",
       "         [-5.8442e+02,  1.1472e+01],\n",
       "         [-5.8421e+02,  1.2093e+01],\n",
       "         [-5.8400e+02,  1.2716e+01],\n",
       "         [-5.8379e+02,  1.3335e+01],\n",
       "         [-5.8359e+02,  1.3954e+01],\n",
       "         [-5.8339e+02,  1.4574e+01],\n",
       "         [-5.8319e+02,  1.5197e+01],\n",
       "         [-5.8299e+02,  1.5818e+01],\n",
       "         [-5.8279e+02,  1.6436e+01],\n",
       "         [-5.8259e+02,  1.7047e+01],\n",
       "         [-5.8239e+02,  1.7657e+01],\n",
       "         [-5.8220e+02,  1.8261e+01],\n",
       "         [-5.8201e+02,  1.8852e+01],\n",
       "         [-5.8182e+02,  1.9437e+01],\n",
       "         [-5.8164e+02,  2.0017e+01],\n",
       "         [-5.8146e+02,  2.0596e+01],\n",
       "         [-5.8127e+02,  2.1173e+01],\n",
       "         [-5.8109e+02,  2.1751e+01],\n",
       "         [-5.8090e+02,  2.2334e+01],\n",
       "         [-5.8072e+02,  2.2922e+01],\n",
       "         [-5.8054e+02,  2.3514e+01],\n",
       "         [-5.8036e+02,  2.4109e+01],\n",
       "         [-5.8018e+02,  2.4702e+01],\n",
       "         [-5.8001e+02,  2.5293e+01],\n",
       "         [-5.7985e+02,  2.5880e+01],\n",
       "         [-5.7968e+02,  2.6498e+01],\n",
       "         [-5.7951e+02,  2.7128e+01],\n",
       "         [-5.7935e+02,  2.7747e+01],\n",
       "         [-5.7919e+02,  2.8343e+01],\n",
       "         [-5.7904e+02,  2.8900e+01],\n",
       "         [-5.7891e+02,  2.9402e+01],\n",
       "         [-5.7880e+02,  2.9845e+01],\n",
       "         [-5.7870e+02,  3.0228e+01],\n",
       "         [-5.7862e+02,  3.0543e+01]],\n",
       "\n",
       "        [[ 3.5116e+03, -1.8349e+03],\n",
       "         [ 3.5099e+03, -1.8338e+03],\n",
       "         [ 3.5083e+03, -1.8328e+03],\n",
       "         [ 3.5066e+03, -1.8317e+03],\n",
       "         [ 3.5050e+03, -1.8307e+03],\n",
       "         [ 3.5033e+03, -1.8296e+03],\n",
       "         [ 3.5017e+03, -1.8286e+03],\n",
       "         [ 3.5000e+03, -1.8275e+03],\n",
       "         [ 3.4984e+03, -1.8265e+03],\n",
       "         [ 3.4967e+03, -1.8254e+03],\n",
       "         [ 3.4950e+03, -1.8244e+03],\n",
       "         [ 3.4934e+03, -1.8233e+03],\n",
       "         [ 3.4917e+03, -1.8223e+03],\n",
       "         [ 3.4900e+03, -1.8212e+03],\n",
       "         [ 3.4882e+03, -1.8201e+03],\n",
       "         [ 3.4865e+03, -1.8190e+03],\n",
       "         [ 3.4847e+03, -1.8180e+03],\n",
       "         [ 3.4830e+03, -1.8169e+03],\n",
       "         [ 3.4812e+03, -1.8158e+03],\n",
       "         [ 3.4795e+03, -1.8147e+03],\n",
       "         [ 3.4777e+03, -1.8137e+03],\n",
       "         [ 3.4760e+03, -1.8126e+03],\n",
       "         [ 3.4742e+03, -1.8116e+03],\n",
       "         [ 3.4725e+03, -1.8105e+03],\n",
       "         [ 3.4707e+03, -1.8095e+03],\n",
       "         [ 3.4689e+03, -1.8085e+03],\n",
       "         [ 3.4672e+03, -1.8074e+03],\n",
       "         [ 3.4654e+03, -1.8064e+03],\n",
       "         [ 3.4636e+03, -1.8053e+03],\n",
       "         [ 3.4618e+03, -1.8043e+03],\n",
       "         [ 3.4600e+03, -1.8032e+03],\n",
       "         [ 3.4582e+03, -1.8022e+03],\n",
       "         [ 3.4563e+03, -1.8011e+03],\n",
       "         [ 3.4545e+03, -1.8001e+03],\n",
       "         [ 3.4527e+03, -1.7991e+03],\n",
       "         [ 3.4508e+03, -1.7980e+03],\n",
       "         [ 3.4490e+03, -1.7970e+03],\n",
       "         [ 3.4472e+03, -1.7960e+03],\n",
       "         [ 3.4453e+03, -1.7950e+03],\n",
       "         [ 3.4435e+03, -1.7940e+03],\n",
       "         [ 3.4417e+03, -1.7930e+03],\n",
       "         [ 3.4398e+03, -1.7919e+03],\n",
       "         [ 3.4379e+03, -1.7909e+03],\n",
       "         [ 3.4359e+03, -1.7898e+03],\n",
       "         [ 3.4340e+03, -1.7887e+03],\n",
       "         [ 3.4321e+03, -1.7877e+03],\n",
       "         [ 3.4304e+03, -1.7867e+03],\n",
       "         [ 3.4289e+03, -1.7859e+03],\n",
       "         [ 3.4275e+03, -1.7851e+03],\n",
       "         [ 3.4264e+03, -1.7845e+03]]], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30b08842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -195.6793,  1155.2272],\n",
       "        [  229.8162,  -769.5313],\n",
       "        [ -578.6198,    30.5431],\n",
       "        [ 3426.3870, -1784.4888]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c1b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x[i][:,:][:,0], x[i][:,:][:,1], c='blue', s=1)\n",
    "plt.scatter(y[i][:,:][:,0], y[i][:,:][:,1], c='red', s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a49e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6b65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
